{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Attempt 1 Outlier Insensitivity\n",
    "Our initial model uses the binary cross entropy loss function. We will investigate the output some alternative probalistic loss functions to see which minimizes the loss on our test set.\n",
    "The functions in contention are: Hinge Loss , KL Divergance , Poisson Class , and Binary Cross Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuilding the model up to the point where the loss function is implemented\n",
    "import pandas as pd\n",
    "# Reading in charity_data.csv as a dataframe\n",
    "charity_df = pd.read_csv('Resources/charity_data.csv')\n",
    "\n",
    "# Dropping the EIN and name columns\n",
    "charity_df.drop(['EIN' , 'NAME'] , axis= 1, inplace= True)\n",
    "\n",
    "# Find the unique Value counts in the Application_Type column\n",
    "type_count = charity_df['APPLICATION_TYPE'].value_counts()\n",
    "\n",
    "# We will set the cut off at 500 , so that application types with less than 500 applications will be aggregated into the \"other\" group\n",
    "less_than_500 = type_count[charity_df['APPLICATION_TYPE'].value_counts() < 500].index\n",
    "\n",
    "# replacing application type with other\n",
    "charity_df['APPLICATION_TYPE'] = charity_df['APPLICATION_TYPE'].replace(less_than_500 , 'Other')\n",
    "\n",
    "# Finding unique value counts in CLASSIFICATION\n",
    "class_count = charity_df['CLASSIFICATION'].value_counts()\n",
    "\n",
    "# Cut of will be set at 1000\n",
    "less_than_1000 = class_count[charity_df['CLASSIFICATION'].value_counts() < 1000].index\n",
    "\n",
    "# Replacing the listed classes with other\n",
    "charity_df['CLASSIFICATION'] = charity_df['CLASSIFICATION'].replace(less_than_1000 , 'other')\n",
    "\n",
    "# Convert Categorical values into numeric\n",
    "numeric_df = pd.get_dummies(charity_df)\n",
    "\n",
    "# Splitting inputs from output\n",
    "y = numeric_df.pop('IS_SUCCESSFUL') # Pop off \"Is_Succesful\" our target column\n",
    "X = numeric_df # the remaining features after the pop off\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Splitting data into training and testing sets\n",
    "X_train , X_test , y_train , y_test = train_test_split(X , y , random_state= 78)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# scaling the data sets\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fitting the scaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 43)                1892      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 43)                1892      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 44        \n",
      "=================================================================\n",
      "Total params: 3,828\n",
      "Trainable params: 3,828\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# Creating our neural network\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Creating our first Dense Layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=43 ,activation= 'relu' , input_dim = 43 )) # there are 43 features that will serve as inputs\n",
    "\n",
    "# Adding our second layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=43 , activation= 'relu' , input_dim = 43))\n",
    "\n",
    "# Creating the output layer\n",
    "nn_model.add(tf.keras.layers.Dense(units = 1 , activation = 'sigmoid'))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.865458"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing loss functions\n",
    "# generating random test ouputs\n",
    "y_true = [0, 1, 0, 0]\n",
    "y_pred = [-18.6, 0.51, 2.94, -12.8]\n",
    "\n",
    "# Binary Cross Entropy\n",
    "bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "bce(y_true, y_pred).numpy()\n",
    "\n",
    "# Hinge Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f61ff51b365b6fb2c14cce9a7b99068f7a2d9ab082ba55f2d8a4c0cff92da04"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
